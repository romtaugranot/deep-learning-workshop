{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K-ZFffzGCzld"
      },
      "outputs": [],
      "source": [
        "!pip install accelerate bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tBqyoPQ3DBHB"
      },
      "outputs": [],
      "source": [
        "import transformers\n",
        "import torch\n",
        "\n",
        "model_id = \"unsloth/llama-3-8b-Instruct-bnb-4bit\"\n",
        "\n",
        "pipeline = transformers.pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model_id,\n",
        "    model_kwargs={\n",
        "        \"torch_dtype\": torch.float16,\n",
        "        \"quantization_config\": {\"load_in_4bit\": True},\n",
        "        \"low_cpu_mem_usage\": True,\n",
        "    },\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "2YxIC3MHic3z"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming 'writer_of_questions.csv' is in your current directory or you provide the correct path.\n",
        "df = pd.read_csv('writer_of_episodes_questions.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "E6e4Pmpzkmr2"
      },
      "outputs": [],
      "source": [
        "prompts = []\n",
        "for index, row in df.iterrows():\n",
        "    question = row['Question']\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"You are a Seinfeld expert, skilled in generating scripts in the iconic style of the show. You understand the characters' distinct personalities, and comedic timing. In addition to writing scripts, you are a trivia master, able to answer detailed questions about the show, such as who said specific lines and who wrote particular episodes\"},\n",
        "        {\"role\": \"system\", \"content\": \"when asked who is the writer of an episode, answer in the following way if there is only one writer: The writer of [name of episode] is [name of writer]\"},\n",
        "        {\"role\": \"system\", \"content\": \"when asked who is the writer of an episode, answer in the following way if there are more than one writer: The writers of [name of episode] are [name of writers]\"},\n",
        "        {\"role\": \"user\", \"content\": question},\n",
        "    ]\n",
        "\n",
        "    prompt = pipeline.tokenizer.apply_chat_template(\n",
        "            messages,\n",
        "            tokenize=False,\n",
        "            add_generation_prompt=True\n",
        "    )\n",
        "\n",
        "    prompts += [prompt]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hNhP-5A7JO4q"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "terminators = [\n",
        "    pipeline.tokenizer.eos_token_id,\n",
        "    pipeline.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
        "]\n",
        "\n",
        "outputs = pipeline(\n",
        "    prompts,\n",
        "    max_new_tokens=256,\n",
        "    eos_token_id=terminators,\n",
        "    do_sample=True,\n",
        "    temperature=0.2,\n",
        "    top_p=0.9,\n",
        ")\n",
        "\n",
        "for index,output in enumerate(outputs):\n",
        "    print([output[\"generated_text\"][len(prompts[index]):]])\n",
        "\n",
        "#questions += [question]\n",
        "#answers += [row['Answer']]\n",
        "#model_answers += [outputs[0][\"generated_text\"][len(prompt):]]\n",
        "\n",
        "#new_df = pd.DataFrame({'Question': questions, 'Answer': answers, 'ModelAnswer': model_answers})\n",
        "#new_df.to_csv('writer_of_episodes_questions_model_answers.csv', mode='w', header=False, index=False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
